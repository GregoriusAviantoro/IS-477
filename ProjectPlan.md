# Project Plan â€“ IS-477

## Overview
This project will use real-world data management skills to solve a practical problem by integrating at least two distinct datasets. The end-to-end process will involve data lifecycle planning, ethical/data compliance, acquisition and cleaning, integration, quality assessment, workflow automation, and reproducible results following best practices taught in IS-477. Our goal is to demonstrate modern data curation and integration in a transparent and FAIR way.

## Research Questions
- What is the core question my project will answer?  
  (Example: "How do weather patterns impact local business revenues in Champaign, IL?")
- Are there secondary questions or hypotheses?

## Team Members and Roles
- Gregorius Aviantoro: (Project lead, scripting, Git/GitHub management)
- [Teammate Name]: (Analysis, documentation, dataset investigation)

## Datasets
- **Dataset 1:** [Name of Dataset]  
  - Description: (What does it contain? Where does it come from?)
  - Access method: (API, CSV download, etc.)
- **Dataset 2:** [Name of Dataset]  
  - Description:
  - Access method:
- Are there other possible sources to add depth (optional/exploratory)?

## Timeline
| Milestone              | Task/Description                  | Responsible        | Due Date        |
|------------------------|-----------------------------------|--------------------|-----------------||
| Team selection         | Confirm team, set roles           | Everyone           | Sep 26, 2025    |
| Project plan           | Draft/upload ProjectPlan.md        | Gregorius          | Oct 7, 2025     |
| Data acquisition       | Obtain datasets                   | [Name]             | [Date]          |
| Data cleaning          | Profile, clean, and document data | [Name]             | [Date]          |
| Data integration       | Integrate sources, analysis setup | [Name]             | [Date]          |
| Status report          | Draft/update StatusReport.md      | [Name]             | Nov 11, 2025    |
| Finalize workflow      | Automate and document workflow    | [Name]             | [Date]          |
| Final report           | Draft/upload README.md & release  | Gregorius/[Name]   | Dec 10, 2025    |

## Constraints
- Data availability or licensing limits
- Time, group size, or software restrictions
- Gaps in personal knowledge/skills (to address in course)

## Known Gaps / Help Needed
- Uncertainty with accessing Dataset 2
- Need guidance on data cleaning best practices or automation scripting
- (List any uncertainties you want instructor/TA feedback on)

## Addressing Course Requirements
- **Data lifecycle**: Will tie workflow to the [chosen model from Module 1] (e.g., CRISP-DM, metadata-driven, etc.).
- **Ethics/data compliance**: Datasets checked for licenses, privacy/confidentiality, and proper use.
- **Collection/acquisition**: Will document and share repeatable data gathering code/scripts.
- **Organization/storage**: Plan to use [relational/db, CSVs, or both], named with clear versioning.
- **Extraction/integration**: Use [Python/pandas, SQL, or merging tools].
- **Quality/cleaning**: Profile using [pandas profiling, OpenRefine, etc.], documenting missing/outlier handling.
- **Automation & provenance**: Scripts (and potentially Snakemake/workflow tool) and documentation for full pipeline.
- **Reproducibility/metadata**: All steps and data locations to be logged; code dependencies (requirements.txt) included.
- **Documentation**: Markdown files and, as required, data dictionary/codebook.

---

*Plan will evolve based on feedback and further investigation as the semester progresses.*
